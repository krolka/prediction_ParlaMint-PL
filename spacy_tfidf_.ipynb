{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFSOGmPZd3XM",
        "outputId": "5fc8c75a-b8c8-4135-934b-ed92224fbd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import re\n",
        "spacy.cli.download('pl_core_news_lg')\n",
        "nlp = spacy.load('pl_core_news_lg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, explained_variance_score, max_error, mean_absolute_error, mean_squared_error, r2_score, roc_curve, roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC,  LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZAJhgUS2HB4"
      },
      "outputs": [],
      "source": [
        "def get_bows(data_tokens_train, data_tokens_test, data_lemmas_train, data_lemmas_test):\n",
        "\n",
        "  #unigrams\n",
        "  #tokens\n",
        "  CountVec = TfidfVectorizer(ngram_range=(1,1))\n",
        "\n",
        "  bow_uni_train = CountVec.fit_transform(data_tokens_train).toarray()\n",
        "  bow_uni_test = CountVec.transform(data_tokens_test).toarray()\n",
        "\n",
        "  #lemmas\n",
        "  CountVec = TfidfVectorizer(ngram_range=(1,1))\n",
        "\n",
        "  bowl_uni_train = CountVec.fit_transform(data_lemmas_train).toarray()\n",
        "  bowl_uni_test = CountVec.transform(data_tokens_test).toarray()\n",
        "\n",
        "\n",
        "  return bow_uni_train, bow_uni_test,  bowl_uni_train, bowl_uni_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c5VE4--eq3N"
      },
      "outputs": [],
      "source": [
        "def prep_features(X_train, X_test):\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  pca = PCA(n_components = 0.9).fit(X_train)\n",
        "  X_train_pca = pca.transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  print(pca.n_components_)\n",
        "\n",
        "  return X_train_pca, X_test_pca\n",
        "\n",
        "\n",
        "def compare_models(X_train, X_test, y_train,y_test, cm_name):\n",
        "\n",
        "  class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "  class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "  print(class_weight_dict)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  best_classifiers = {}\n",
        "\n",
        "  #svc\n",
        "  svc = SVC(class_weight = class_weight_dict, decision_function_shape='ovo', max_iter = 100000)\n",
        "  svc = svc.fit(X_train, y_train)\n",
        "  svc_pred = svc.predict(X_test)\n",
        "  print('svc classification results')\n",
        "  print(classification_report(y_test, svc_pred, zero_division = 1))\n",
        "  best_classifiers['svc'] = svc_pred\n",
        "\n",
        "  print('_'*200)\n",
        "\n",
        "  #nb\n",
        "  nb = GaussianNB()\n",
        "  nb.class_prior_ = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values())\n",
        "  nb = nb.fit(X_train, y_train)\n",
        "  nb_pred = nb.predict(X_test)\n",
        "  print('NB classification results')\n",
        "  print(classification_report(y_test, nb_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "  best_classifiers['nb'] = nb_pred\n",
        "\n",
        "  mnb = MultinomialNB(force_alpha=True)\n",
        "  mnb.fit(X_train, y_train)\n",
        "  mnb_pred = mnb.predict(X_test)\n",
        "  print('MNB classification results')\n",
        "  print(classification_report(y_test, mnb_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "  best_classifiers['mnb'] = mnb_pred\n",
        "\n",
        "  #random forest\n",
        "  rf = RandomForestClassifier(class_weight = class_weight_dict)\n",
        "  rf = rf.fit(X_train, y_train)\n",
        "  rf_pred = rf.predict(X_test)\n",
        "  print('RF classification results')\n",
        "  print(classification_report(y_test, rf_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['rf'] = rf_pred\n",
        "\n",
        "\n",
        "\n",
        "  #multilayer\n",
        "  mlp = MLPClassifier(alpha = 0.05, learning_rate = 'adaptive')\n",
        "  mlp.class_prior_ = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values())\n",
        "  mlp = mlp.fit(X_train, y_train)\n",
        "  mlp_pred = mlp.predict(X_test)\n",
        "  print('mlp classification results')\n",
        "  print(classification_report(y_test, mlp_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "  best_classifiers['mlp'] = mlp_pred\n",
        "\n",
        "  #dt\n",
        "  dt = DecisionTreeClassifier(random_state = 0, max_depth = 7, class_weight = class_weight_dict)\n",
        "  dt = dt.fit(X_train, y_train)\n",
        "  dt_pred = dt.predict(X_test)\n",
        "  print('dt classification results')\n",
        "  print(classification_report(y_test, dt_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "  best_classifiers['dt'] = dt_pred\n",
        "\n",
        "\n",
        "  #sb\n",
        "  ab = AdaBoostClassifier()\n",
        "  ab.class_prior_ = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values())\n",
        "  ab = ab.fit(X_train, y_train)\n",
        "  ab_pred = ab.predict(X_test)\n",
        "  print('AB classification results')\n",
        "  print(classification_report(y_test, ab_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "  best_classifiers['ab'] = ab_pred\n",
        "\n",
        "\n",
        "  #logistic regression\n",
        "  reg = LogisticRegression(max_iter = 10000, class_weight = class_weight_dict, multi_class = 'multinomial')\n",
        "  reg = reg.fit(X_train, y_train)\n",
        "  reg_pred = reg.predict(X_test)\n",
        "  best_classifiers['reg'] = reg_pred\n",
        "\n",
        "  print('REG classification results')\n",
        "  print(classification_report(y_test, reg_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "\n",
        "  #knn\n",
        "  neigh = KNeighborsClassifier(n_neighbors = 4)\n",
        "  neigh.class_prior_ = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values())\n",
        "  neigh = neigh.fit(X_train_pca, y_train)\n",
        "  knn_pred = neigh.predict(X_test_pca)\n",
        "\n",
        "  best_classifiers['knn'] = knn_pred\n",
        "\n",
        "  print('KNN classification results')\n",
        "  print(classification_report(y_test, knn_pred, zero_division = 1))\n",
        "  print('_'*200)\n",
        "\n",
        "  best_classifier = input('pick best classifier: ')\n",
        "\n",
        "  cm = confusion_matrix(y_test, best_classifiers[best_classifier])\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  plt.figure(figsize = [10,10])\n",
        "  ax = sns.heatmap(cm, annot = True, fmt = 'd', annot_kws = {'size': 20} , cmap = sns.color_palette(\"Blues\", as_cmap=True))\n",
        "  ax.xaxis.set_ticklabels(['KO', 'PiS', 'Konfederacja', 'Lewica'], fontsize = 20)\n",
        "  ax.yaxis.set_ticklabels(['KO', 'PiS', 'Konfederacja', 'Lewica'], fontsize = 20)\n",
        "  ax.set_xlabel('Predicted label', fontsize = 20)\n",
        "  ax.set_ylabel('True label', fontsize = 20)\n",
        "  plt.savefig(cm_name)\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JwQ0y8z8czt"
      },
      "source": [
        "# loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmdeH2b3XMO0",
        "outputId": "cbb4d390-e3c6-4c5e-b208-1753ad4ed240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zzHI3u9DjMb"
      },
      "outputs": [],
      "source": [
        "path = './drive/MyDrive/Master/thesis_codes/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMpHM4SDjMb"
      },
      "outputs": [],
      "source": [
        "data_sejm = pd.read_csv(path+'data_sejm_spacy.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TxSo_syA0hR"
      },
      "outputs": [],
      "source": [
        "data_sejm = data_sejm.dropna(subset=['Speaker_party'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUGaF95nkcpv"
      },
      "outputs": [],
      "source": [
        "data_sejm  = data_sejm [data_sejm['Speaker_party'].isin(['KO','PiS','Konfederacja','Lewica'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3xFXKq5DjMb"
      },
      "outputs": [],
      "source": [
        "sample_data = data_sejm.sample(n = 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wS_njqlPf4E"
      },
      "outputs": [],
      "source": [
        "sample_data = sample_data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QlAXY9dIW1W"
      },
      "outputs": [],
      "source": [
        "party_numbers = []\n",
        "for p in sample_data['Speaker_party']:\n",
        "  if p == 'KO':\n",
        "    party_numbers.append(0)\n",
        "  if p == 'PiS':\n",
        "    party_numbers.append(1)\n",
        "  if p == 'Konfederacja':\n",
        "    party_numbers.append(2)\n",
        "  if p == 'Lewica':\n",
        "    party_numbers.append(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb0rewy3IcJ9"
      },
      "outputs": [],
      "source": [
        "sample_data['Party_tag'] = party_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvveBrmoIWY-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sample_data['tokens'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgb61VWTLXjU"
      },
      "outputs": [],
      "source": [
        "X_trainl, X_testl, y_trainl, y_testl = train_test_split(sample_data['lemmas'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAWrlUOl2HB4"
      },
      "outputs": [],
      "source": [
        "bow_uni_train, bow_uni_test, bowl_uni_train, bowl_uni_test = get_bows(X_train, X_test, X_trainl, X_testl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PxV5Lv9Natp"
      },
      "outputs": [],
      "source": [
        "X_train_pca, X_test_pca = prep_features(bow_uni_train, bow_uni_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STRcs9DKXmUB"
      },
      "outputs": [],
      "source": [
        "X_trainl_pca, X_testl_pca = prep_features(bowl_uni_train, bowl_uni_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NucPfWemst-"
      },
      "outputs": [],
      "source": [
        "compare_models(X_train_pca, X_test_pca, y_train,y_test, 'bow_spacy_party_sejm.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYFpEsyotYGn"
      },
      "outputs": [],
      "source": [
        "compare_models(X_trainl_pca, X_testl_pca, y_trainl, y_testl, 'bowl_spacy_party_sejm.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOXvQdh-2cee"
      },
      "source": [
        "# balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvs4sK3aryRI"
      },
      "outputs": [],
      "source": [
        "data_pis = data_sejm.loc[data_sejm['Speaker_party'] == 'PiS'].sample(n = 2000)\n",
        "data_ko = data_sejm.loc[data_sejm['Speaker_party'] == 'KO'].sample(n = 2000)\n",
        "data_konf = data_sejm.loc[data_sejm['Speaker_party'] == 'Konfederacja'].sample(n = 2000)\n",
        "data_lew = data_sejm.loc[data_sejm['Speaker_party'] == 'Lewica'].sample(n = 2000)\n",
        "sample_data = pd.concat([data_pis, data_ko, data_konf, data_lew], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qDqcuG7ryRK"
      },
      "outputs": [],
      "source": [
        "sample_data = sample_data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-uglGXq2wcH"
      },
      "outputs": [],
      "source": [
        "party_numbers = []\n",
        "for p in sample_data['Speaker_party']:\n",
        "  if p == 'KO':\n",
        "    party_numbers.append(0)\n",
        "  if p == 'PiS':\n",
        "    party_numbers.append(1)\n",
        "  if p == 'Konfederacja':\n",
        "    party_numbers.append(2)\n",
        "  if p == 'Lewica':\n",
        "    party_numbers.append(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJOkCzBR2wcJ"
      },
      "outputs": [],
      "source": [
        "sample_data['Party_tag'] = party_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuYvLpDW2wcJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sample_data['tokens'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWewPL202wcJ"
      },
      "outputs": [],
      "source": [
        "X_trainl, X_testl, y_trainl, y_testl = train_test_split(sample_data['lemmas'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2O2smAj2wcL"
      },
      "outputs": [],
      "source": [
        "bow_uni_train, bow_uni_test, bowl_uni_train, bowl_uni_test = get_bows(X_train, X_test, X_trainl, X_testl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5TY53NyCz71"
      },
      "outputs": [],
      "source": [
        "X_train_pca, X_test_pca = prep_features(bow_uni_train, bow_uni_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn2jeLAjCz72"
      },
      "outputs": [],
      "source": [
        "compare_models(X_train_pca, X_test_pca, y_train,y_test, 'bow_spacy_party_sejm_balanced.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHPDV8F72wcO"
      },
      "outputs": [],
      "source": [
        "X_trainl_pca, X_testl_pca = prep_features(bowl_uni_train, bowl_uni_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxPPmYNh2wcP"
      },
      "outputs": [],
      "source": [
        "compare_models(X_trainl_pca, X_testl_pca, y_trainl, y_testl, 'bowl_spacy_party_sejm_balanced.jpg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}