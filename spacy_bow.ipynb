{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library import"
      ],
      "metadata": {
        "id": "v_DgBpcisAm5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFSOGmPZd3XM",
        "outputId": "0e303e9e-066a-4d26-c1f0-eaecc36d4207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import os\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import re\n",
        "spacy.cli.download('pl_core_news_lg')\n",
        "nlp = spacy.load('pl_core_news_lg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, explained_variance_score, max_error, mean_absolute_error, mean_squared_error, r2_score, roc_curve, roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC,  LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.utils import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "G5gfgxo6sDfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHd3AqnCHrm8"
      },
      "outputs": [],
      "source": [
        "def get_bows(data_tokens_train, data_tokens_test, data_lemmas_train, data_lemmas_test):\n",
        "\n",
        "  #unigrams\n",
        "  #tokens\n",
        "  CountVec = CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "  bow_uni_train = CountVec.fit_transform(data_tokens_train).toarray()\n",
        "  bow_uni_test = CountVec.transform(data_tokens_test).toarray()\n",
        "\n",
        "  #lemmas\n",
        "  CountVec = CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "  bowl_uni_train = CountVec.fit_transform(data_lemmas_train).toarray()\n",
        "  bowl_uni_test = CountVec.transform(data_tokens_test).toarray()\n",
        "\n",
        "\n",
        "  return bow_uni_train, bow_uni_test,  bowl_uni_train, bowl_uni_test\n",
        "\n",
        "def prep_features(X_train, X_test):\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  pca = PCA(n_components = 0.9).fit(X_train)\n",
        "  X_train_pca = pca.transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  print(pca.n_components_)\n",
        "\n",
        "  return X_train_pca, X_test_pca\n",
        "\n",
        "\n",
        "def compare_models(X_train, X_test, y_train,y_test, cm_name):\n",
        "\n",
        "  class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "  class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "  print(class_weight_dict)\n",
        "\n",
        "  best_classifiers = {}\n",
        "\n",
        "  #svc\n",
        "  svc = SVC(class_weight = class_weight_dict)\n",
        "  svc = svc.fit(X_train, y_train)\n",
        "  svc_pred = svc.predict(X_test)\n",
        "  print('svc classification results')\n",
        "  print(classification_report(y_test, svc_pred))\n",
        "  best_classifiers['svc'] = svc_pred\n",
        "\n",
        "  print('_'*200)\n",
        "  #lsvc\n",
        "  lsvc = LinearSVC(class_weight = class_weight_dict)\n",
        "  lsvc = lsvc.fit(X_train, y_train)\n",
        "  lsvc_pred = lsvc.predict(X_test)\n",
        "  print('lsvc classification results')\n",
        "  print(classification_report(y_test, lsvc_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['lsvc'] = lsvc_pred\n",
        "\n",
        "  #nb\n",
        "  nb = GaussianNB()#priors = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values()))\n",
        "  nb = nb.fit(X_train, y_train)\n",
        "  nb_pred = nb.predict(X_test)\n",
        "  print('NB classification results')\n",
        "  print(classification_report(y_test, nb_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['nb'] = nb_pred\n",
        "\n",
        "  #random forest\n",
        "  rf = RandomForestClassifier(class_weight = class_weight_dict)\n",
        "  rf = rf.fit(X_train, y_train)\n",
        "  rf_pred = rf.predict(X_test)\n",
        "  print('RF classification results')\n",
        "  print(classification_report(y_test, rf_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['rf'] = rf_pred\n",
        "\n",
        "\n",
        "  #multilayer\n",
        "\n",
        "  mlp = MLPClassifier(alpha = 0.05)\n",
        "  mlp.class_prior_ = np.array(list(class_weight_dict.values())) / sum(class_weight_dict.values())\n",
        "  mlp = mlp.fit(X_train, y_train)\n",
        "  mlp_pred = mlp.predict(X_test)\n",
        "  print('mlp classification results')\n",
        "  print(classification_report(y_test, mlp_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['mlp'] = mlp_pred\n",
        "\n",
        "  #dt\n",
        "  dt = DecisionTreeClassifier(class_weight = class_weight_dict)\n",
        "  dt = dt.fit(X_train, y_train)\n",
        "  dt_pred = dt.predict(X_test)\n",
        "  print('dt classification results')\n",
        "  print(classification_report(y_test, dt_pred))\n",
        "\n",
        "\n",
        "\n",
        "  #ab\n",
        "  ab = AdaBoostClassifier()\n",
        "  ab = ab.fit(X_train, y_train)\n",
        "  ab_pred = ab.predict(X_test)\n",
        "  print('AB classification results')\n",
        "  print(classification_report(y_test, ab_pred))\n",
        "  print('_'*200)\n",
        "  best_classifiers['ab'] = ab_pred\n",
        "\n",
        "\n",
        "  #logistic regression\n",
        "  reg = LogisticRegression(max_iter = 10000, class_weight = class_weight_dict)\n",
        "  reg = reg.fit(X_train, y_train)\n",
        "  reg_pred = reg.predict(X_test)\n",
        "  best_classifiers['reg'] = reg_pred\n",
        "\n",
        "  print('REG classification results')\n",
        "  print(classification_report(y_test, reg_pred))\n",
        "  print('_'*200)\n",
        "\n",
        "  best_classifier = input('pick best classifier: ')\n",
        "\n",
        "  cm = confusion_matrix(y_test, best_classifiers[best_classifier])\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  plt.figure(figsize = [10,10])\n",
        "  ax = sns.heatmap(cm, annot = True, fmt = 'd', annot_kws = {'size': 20} , cmap = sns.color_palette(\"Blues\", as_cmap=True))\n",
        "  ax.xaxis.set_ticklabels(['Coalition', 'Opposition'], fontsize = 20)\n",
        "  ax.yaxis.set_ticklabels(['Coalition', 'Opposition'], fontsize = 20)\n",
        "  ax.set_xlabel('Predicted label', fontsize = 20)\n",
        "  ax.set_ylabel('True label', fontsize = 20)\n",
        "  plt.savefig(cm_name)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n"
      ],
      "metadata": {
        "id": "H5DZ_2zUsIr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H0TAHMsd9_z",
        "outputId": "36a6cb0a-7bd9-456f-e229-5c41d91ef8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zzHI3u9DjMb"
      },
      "outputs": [],
      "source": [
        "path = './drive/MyDrive/Master/thesis_codes/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqdy4zXZs35k"
      },
      "outputs": [],
      "source": [
        "data_sejm = pd.read_csv(path+'data_senat_spacy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing non coallition/opposition speakers"
      ],
      "metadata": {
        "id": "tdNAtx4zsMFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TxSo_syA0hR"
      },
      "outputs": [],
      "source": [
        "data_sejm = data_sejm.dropna(subset=['Party_status'])\n",
        "data_sejm = data_sejm[data_sejm.astype(str)['lemmas'] != '[]']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the subset"
      ],
      "metadata": {
        "id": "Zgp1pT30sR8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_WV1Na1q-vA"
      },
      "outputs": [],
      "source": [
        "sample_data = data_sejm.sample(n = 10000)\n",
        "sample_data = sample_data.sample(frac=1).reset_index(drop=True)\n",
        "sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning class labels"
      ],
      "metadata": {
        "id": "7jL9almesUE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QlAXY9dIW1W"
      },
      "outputs": [],
      "source": [
        "party_numbers = []\n",
        "for p in sample_data['Party_status']:\n",
        "  if p == 'Coalition':\n",
        "    party_numbers.append(0)\n",
        "  elif p == 'Opposition':\n",
        "    party_numbers.append(1)\n",
        "\n",
        "sample_data['Party_tag'] = party_numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the dataset"
      ],
      "metadata": {
        "id": "ePYIO7nusZ5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvveBrmoIWY-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sample_data['tokens'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkNoWEV2ClKN"
      },
      "outputs": [],
      "source": [
        "X_trainl, X_testl, y_trainl, y_testl= train_test_split(sample_data['lemmas'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the features"
      ],
      "metadata": {
        "id": "hctYzIHUsc7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GxJoFl3J5fQ"
      },
      "outputs": [],
      "source": [
        "bow_uni_train, bow_uni_test, bowl_uni_train, bowl_uni_test = get_bows(X_train, X_test, X_trainl, X_testl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOW"
      ],
      "metadata": {
        "id": "ercuZec1sjs5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PxV5Lv9Natp"
      },
      "outputs": [],
      "source": [
        "X_train_pca, X_test_pca = prep_features(bow_uni_train, bow_uni_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOWL"
      ],
      "metadata": {
        "id": "mSHKzZWJslSC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STRcs9DKXmUB"
      },
      "outputs": [],
      "source": [
        "X_trainl_pca, X_testl_pca = prep_features(bowl_uni_train, bowl_uni_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "LV-oRRDSsmbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NucPfWemst-"
      },
      "outputs": [],
      "source": [
        "compare_models(X_train_pca, X_test_pca, y_train,y_test, 'bow_morf_left_right.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(X_trainl_pca, X_testl_pca, y_trainl,y_testl, 'bow_morf_left_right.jpg')"
      ],
      "metadata": {
        "id": "iW92PJF58yhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balanced set\n"
      ],
      "metadata": {
        "id": "Mzurd9ySLNyb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvs4sK3aryRI"
      },
      "outputs": [],
      "source": [
        "data_pis = data_sejm.loc[data_sejm['Party_status'] == 'Coalition'].sample(n = 5000)\n",
        "data_ko = data_sejm.loc[data_sejm['Party_status'] == 'Opposition'].sample(n = 5000)\n",
        "sample_data = pd.concat([data_pis, data_ko], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qDqcuG7ryRK"
      },
      "outputs": [],
      "source": [
        "sample_data = sample_data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzA1vKQ7b9YY"
      },
      "outputs": [],
      "source": [
        "party_numbers = []\n",
        "for p in sample_data['Party_status']:\n",
        "  if p == 'Coalition':\n",
        "    party_numbers.append(0)\n",
        "  elif p == 'Opposition':\n",
        "    party_numbers.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAQrxah5b9Yc"
      },
      "outputs": [],
      "source": [
        "sample_data['Party_tag'] = party_numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the dataset"
      ],
      "metadata": {
        "id": "u4EH6Ja6LXdB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDbe7BJyLXdE"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sample_data['tokens'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdzSjSwVLXdF"
      },
      "outputs": [],
      "source": [
        "X_trainl, X_testl, y_trainl, y_testl= train_test_split(sample_data['lemmas'], sample_data['Party_tag'], test_size=0.2, stratify = sample_data['Party_tag']  ,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the features"
      ],
      "metadata": {
        "id": "fuZaONENLXdF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0nkXpDILXdG"
      },
      "outputs": [],
      "source": [
        "bow_uni_train, bow_uni_test, bowl_uni_train, bowl_uni_test = get_bows(X_train, X_test, X_trainl, X_testl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOW"
      ],
      "metadata": {
        "id": "hvVW9q_ILXdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A348274_LXdG"
      },
      "outputs": [],
      "source": [
        "X_train_pca, X_test_pca = prep_features(bow_uni_train, bow_uni_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOWL"
      ],
      "metadata": {
        "id": "VfqKB2emLXdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzP4NAMPLXdH"
      },
      "outputs": [],
      "source": [
        "X_trainl_pca, X_testl_pca = prep_features(bowl_uni_train, bowl_uni_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "kBewPB-wLXdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOW"
      ],
      "metadata": {
        "id": "jgbxe9TWLXdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qq7V0muLXdH"
      },
      "outputs": [],
      "source": [
        "compare_models(X_train_pca, X_test_pca, y_train,y_test, 'bow_morf_left_right.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOWL"
      ],
      "metadata": {
        "id": "h3OXNMutLXdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQWWRIOfLXdI"
      },
      "outputs": [],
      "source": [
        "compare_models(X_trainl_pca, X_testl_pca, y_trainl, y_testl, 'bowl_morf_left_right.jpg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}