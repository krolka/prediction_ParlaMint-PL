{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE2aRHL2JeAk",
        "outputId": "b22ab83b-0846-4674-86a7-1bfcfe253003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: morfeusz2 in /usr/local/lib/python3.10/dist-packages (1.99.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install morfeusz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZuKCPka-Xr",
        "outputId": "18a19f8d-8874-46ce-d44d-fe10b78d18ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import re\n",
        "spacy.cli.download('pl_core_news_lg')\n",
        "nlp = spacy.load('pl_core_news_lg')\n",
        "import morfeusz2\n",
        "from numpy import save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JwQ0y8z8czt"
      },
      "source": [
        "# loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H0TAHMsd9_z",
        "outputId": "6e158ad6-43cf-4619-8901-b0cd4447d0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcLmqmdneAPY"
      },
      "outputs": [],
      "source": [
        "path = './drive/MyDrive/Master/thesis_codes/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh157_AQPFjN"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(path+'data_senat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPzzbXwTVyOt"
      },
      "outputs": [],
      "source": [
        "morf = morfeusz2.Morfeusz(expand_tags=True, separate_numbering=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6PmpcshKr3X"
      },
      "outputs": [],
      "source": [
        "all_tokens = []\n",
        "all_lemmas = []\n",
        "\n",
        "pos_remove = ['INTERP', 'INTERJ', 'PRED', 'SYM', 'NUM', '_SP', 'romandig', 'NUMCOL', 'XXX']\n",
        "\n",
        "for speech in data['processed_speech']:\n",
        "\n",
        "  text = re.sub(r'\\[\\[.*?\\]\\]', '', speech.lower())\n",
        "  text = nlp(text)\n",
        "  tokens = [token.text for token in text]\n",
        "\n",
        "  tok = []\n",
        "  lem = []\n",
        "  for token in tokens:\n",
        "    analysis = morf.analyse(token)\n",
        "\n",
        "    try:\n",
        "      if re.search(r'^([^:]+)',analysis[0][2][2]).group(0) in pos_remove: #or analysis[0][2][0] in mc :\n",
        "        #print(analysis[0][2][0], re.search(r'^([^:]+)', analysis[0][2][1]).group(0), re.search(r'^([^:]+)', analysis[0][2][2]).group(0))\n",
        "        pass\n",
        "      else:\n",
        "          #print(analysis[0][2][0], re.search(r'^([^:]+)', analysis[0][2][1]).group(0), re.search(r'^([^:]+)', analysis[0][2][2]).group(0))\n",
        "          tok.append(analysis[0][2][0])\n",
        "          lem.append(re.search(r'^([^:]+)', analysis[0][2][1]).group(0))\n",
        "\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "  all_tokens.append(tok)\n",
        "  all_lemmas.append(lem)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokens'] = all_tokens\n",
        "data['lemmas'] = all_lemmas"
      ],
      "metadata": {
        "id": "kTO4SNfQmYmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_np = np.array(all_tokens, dtype = list)\n",
        "lemmas_np = np.array(all_lemmas, dtype = list)"
      ],
      "metadata": {
        "id": "61ASQUaFqXZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save('tokens_senat_morf.npy', tokens_np)\n",
        "save('lemmas_senat_morf.npy', lemmas_np)"
      ],
      "metadata": {
        "id": "JM3YGTrySZop"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}